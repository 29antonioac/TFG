Se introducen las herramientas matemáticas necesarias para la consecución de este trabajo.

<<setup05M, cache = FALSE, include = FALSE>>=
set.seed(1254221004)
read_chunk("../scripts/05_Desarrollo_Matematicas.R")
@

\subsection{Introducción al problema}

Parafraseando a~\cite{Abu-Mostafa:2012:LD:2207825}, si a un niño pequeño se le pregunta si hay un árbol
en una foto, lo más probable es que dé la respuesta correcta. Si a uno algo mayor
se le pregunta ``¿Qué es un árbol'', posiblemente no sabrá contestar o su respuesta
no sea muy útil. Los seres humanos no han aprendido qué es un árbol con una definición
matemática, sino viendo árboles. Han aprendido desde los \emph{datos}.

Este tipo de aprendizaje puede ser modelado matemáticamente para solucionar una gran
cantidad de problemas en ciencia, ingeniería, economía, \ldots, etc. Esta rama de
las matemáticas se llama \emph{Aprendizaje Estadístico}.

Matemáticamente, el problema del aprendizaje es, dado un conjunto de puntos de entrada
$\mathcal{X} \in \mathbb{R}^d$, un espacio de salida $\mathcal{Y}$, una función objetivo
\textbf{desconocida}$f:\mathcal{X} \rightarrow \mathcal{Y}$ y $N$ muestras
$\big((x_1,y_1),\ldots,(x_N,y_N) \big)$
tal que $f(x_i) = y_i, \; i = 1,\ldots,N$,
se desea conseguir una función de un determinado espacio de hipótesis,
$g \in \mathcal{H}$ que se asemeje todo lo posible a la función objetivo
$f$, $g \approx f$.

% Tengo que explicar matemáticamente los tres problemas.
% No sé si para ser algo matemático es la mejor introducción posible.
\improvement{Repasar introducción}

En el aprendizaje se distinguen muchos problemas, siendo tres los más conocidos:
\begin{itemize}
  \item Regresión.
  \item Clasificación.
  \item Estimación de densidad.
\end{itemize}
\change{Introducir los 3 problemas matemáticamente}

Un ejemplo de clasificación sería el siguiente:
sea $\mathcal{X} \subseteq [0,1] \times [0,1]$ e $\mathcal{Y} = \{+1,-1\}$ el espacio
de salida, el cual se puede considerar sí/no, $f$ la función objetivo.
Generando muestras aleatorias, un ejemplo sencillo sería el de la
figura~\ref{fig:dataExample}. En lenguaje natural, tenemos dos características
con las que se puede decidir si un correo electrónico entrante es spam, por ejemplo.
Se necesita una función $g$ que cumpla que $\forall x \in \mathcal{X}$, $g(x) = f(x)$.
Intuitivamente, en el caso de clasificación se busca una función que \emph{separe}
los conjuntos de datos con distintas etiquetas. ¿Existe un separador para este conjunto?
En este caso, \textbf{sí}, siendo además el más sencillo, un separador \emph{lineal}.
Así se puede ver en la figura~\ref{fig:classificationExample}.

<<randomLine, include = FALSE>>=
@

<<signOfPoint, include = FALSE>>=
@

<<dataExample, echo = FALSE, fig.cap="Datos de ejemplo">>=
@

<<classificationExample, echo = FALSE, fig.cap="Primer clasificador">>=
@

En este sencillo caso se puede deducir lo siguiente: en un lado de la recta obtenida
se tienen todos los datos con etiquetas $1$ y en el otro los que tienen etiquetas $-1$.
A los conjuntos de datos que cumplen esto los llamaremos \emph{linealmente separables}.
Este hecho no es lo usual en un problema de aprendizaje real. Ni siquiera se sabe
a priori si, ante nuevos datos, esta recta los seguirá separando correctamente.
Incluso, ante nuevos datos, el conjunto podría pasar a ser no linealmente separable.

\subsection{Factibilidad del aprendizaje}

El aprendizaje estadístico busca \emph{obtener información desde los datos},
utilizando para ello técnicas estadísticas. Se empezará estudiando una cuestión
que se ha planteado antes por encima: ante la llegada de nuevos datos, ¿se tiene
un modelo adecuado? ¿Es factible aprender?

\begin{definicion}
  Error dentro de la muestra ($E_{in}$). Es la fracción de $\mathcal{D}$ donde
  la función escogida $h$ y la objetivo $f$ difieren. $\chi(condicion)$ es la
  función indicadora: vale 1 si la condición es cierta y 0 si no lo es.

  \[
    E_{in}(h) = \frac{1}{N} \sum\limits_{n=1}^N \chi(h(x_n) \neq f(x_n))
  \]
\end{definicion}

\begin{definicion}
  Error fuera de la muestra ($E_{out}$). Es la probabilidad, basada en la distribución
  de $\mathcal{X}$, de que la función escogida $h$ y la objetivo $f$ difieren.

  \[
    E_{out}(h) = \mathbb{P}[h(\textbf{x}) \neq f(\textbf{x})]
  \]
\end{definicion}

\unsure{Justificar que E\_out es la esperanza de E\_in}

% Justificar que E_out es la esperanza de E_in

\begin{teorema}[Desigualdad de Hoeffding]
  Si $X_1, X_2, \ldots, X_n$ son independientes y $a_i \leq X_i \leq b_i \; (i=1,2,\ldots,n)$,
  entonces para $\epsilon>0$ se da:
  \[
    \mathbb{P}\left[ \bar{X} - \mathbb{E}[\bar{X}] \geq \epsilon \right] \leq
    e^{\frac{-2 n^2 \epsilon^2}{\sum\limits_{i=1}^n(b_i-a_i)^2}}
  \]
\end{teorema}

\begin{proof}
  Demostración
\end{proof}

\begin{corolario}
  \label{cor:hoeffdingH}
  Si $X_1, X_2, \ldots, X_n$ son independientes y $0 \leq X_i \leq 1 \; (i=1,2,\ldots,n)$,
  entonces para $\epsilon>0$ y una función $h$ se da:
  \[
    \mathbb{P}\left[ | E_{in}(h) - E_{out}(h) | \geq \epsilon \right] \leq
    2 e^{-2 n \epsilon^2}
  \]
\end{corolario}

\begin{proof}
  Demostración. $a_i = 0\; b_i = 1$. Deducir simetría.
\end{proof}

\info{No olvidar demostraciones!}

Todo lo anterior tiene una gran limitación: se está fijando una función $h$ de
antemano. Al fijarla previamente, esta probabilidad depende del conjunto
de datos aleatorio $\mathcal{D}$.

Consideremos un espacio $\mathcal{H}$ con un número finito de hipótesis.

\[
  \mathcal{H} = \{h_1, h_2, \ldots, h_M\}
\]

Cuando se aplica un algoritmo de aprendizaje sobre este conjunto $\mathcal{H}$,
la hipótesis final $g \in \mathcal{H}$ está basada en el conjunto de datos
$\mathcal{D}$, por lo que a la conclusión que se pretende llegar no es exactamente
la del corolario~\ref{cor:hoeffdingH}, sino que se precisa eliminar la hipótesis
\emph{para una función fija}.

\begin{corolario}
  \label{cor:hoeffdingG}
  Si $X_1, X_2, \ldots, X_n$ son independientes y $0 \leq X_i \leq 1 \; (i=1,2,\ldots,n)$,
  entonces para $\epsilon>0$ y una función $g \in \mathcal{H}$ con
  $|\mathcal{H}| = M$ se da:
  \[
    \mathbb{P}\left[ | E_{in}(g) - E_{out}(g) | \geq \epsilon \right] \leq
    2 M e^{-2 n \epsilon^2}
  \]
\end{corolario}

\begin{proof}
  Por como está definida $g$, se tiene que
  \begin{align*}
    |E_{in}(g) - E_{out}(g)| \geq \epsilon \Rightarrow & \; |E_{in}(h_1) - E_{out}(h_1)| \geq \epsilon \\
                              & \vee |E_{in}(h_2) - E_{out}(h_2)| \geq \epsilon \\
                              & \cdots \\
                              & \vee |E_{in}(h_M) - E_{out}(h_M)| \geq \epsilon
  \end{align*}
  Ahora usaremos dos reglas básicas en probabilidad:
  \begin{itemize}
    \item Si $\mathcal{E}_1 \Rightarrow \mathcal{E}_2$ son eventos, entonces
    $\mathbb{P}[\mathcal{E}_1] \leq \mathbb{P}[\mathcal{E}_2]$
    \item Si tenemos $\mathcal{E}_1, \mathcal{E}_2, \ldots, \mathcal{E}_M$ eventos,
    entonces $\mathbb{P}[\mathcal{E}_1 \vee \mathcal{E}_2 \vee \ldots \vee \mathcal{E}_M]
    \leq \mathbb{P}[\mathcal{E}_1] + \mathbb{P}[\mathcal{E}_2] + \ldots + \mathbb{P}[\mathcal{E}_M]$
  \end{itemize}
  Utilizando estas dos reglas es claro que
  \begin{align*}
    \mathbb{P}[|E_{in}(g) - E_{out}(g)| \geq \epsilon] \Rightarrow & \; \mathbb{P}[|E_{in}(h_1) - E_{out}(h_1)| \geq \epsilon \\
                              & \vee |E_{in}(h_2) - E_{out}(h_2)| \geq \epsilon \\
                              & \cdots \\
                              & \vee |E_{in}(h_M) - E_{out}(h_M)| \geq \epsilon ] \\
                              \leq & \sum\limits_{m=1}^M \mathbb{P}[|E_{in}(h_M) - E_{out}(h_M)| \geq \epsilon]
  \end{align*}
  Aplicando la desigualdad de Hoeffding del corolario~\ref{cor:hoeffdingH} a cada uno de los
  $M$ términos, se acota cada uno por $e^{2N \epsilon^2}$. Sumando todo queda
  \[
  \mathbb{P}\left[ | E_{in}(g) - E_{out}(g) | \geq \epsilon \right] \leq
  2 M e^{-2 n \epsilon^2}
  \]
\end{proof}

% Meter Hoeffding general, con g
% Concluir con la factibilidad con H finito, pag 25-26.

\subsection{Generalización: Teoría de Vapnik-Chervonenkis}

\subsection{Sobreajuste}

\subsection{Modelos de árboles: Boosting}
