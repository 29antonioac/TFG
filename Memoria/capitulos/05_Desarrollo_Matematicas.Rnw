Se introducen las herramientas matemáticas necesarias para la consecución de este trabajo.

<<setup05M, cache = FALSE, include = FALSE>>=
set.seed(1254221004)
read_chunk("../scripts/05_Desarrollo_Matematicas.R")
@

\subsection{Introducción al problema}

Parafraseando a~\cite{Abu-Mostafa:2012:LD:2207825}, si a un niño pequeño se le pregunta si hay un árbol
en una foto, lo más probable es que dé la respuesta correcta. Si a uno algo mayor
se le pregunta ``¿Qué es un árbol'', posiblemente no sabrá contestar o su respuesta
no sea muy útil. Los seres humanos no han aprendido qué es un árbol con una definición
matemática, sino viendo árboles. Han aprendido desde los \emph{datos}.

Este tipo de aprendizaje puede ser modelado matemáticamente para solucionar una gran
cantidad de problemas en ciencia, ingeniería, economía, \ldots, etc. Esta rama de
las matemáticas se llama \emph{Aprendizaje Estadístico}.

Matemáticamente, el problema del aprendizaje es, dado un conjunto de puntos de entrada
$\mathcal{X} \in \mathbb{R}^d$, un espacio de salida $\mathcal{Y}$, una función objetivo
\textbf{desconocida}$f:\mathcal{X} \rightarrow \mathcal{Y}$ y $N$ muestras
$\big((x_1,y_1),\ldots,(x_N,y_N) \big)$
tal que $f(x_i) = y_i, \; i = 1,\ldots,N$,
se desea conseguir una función de un determinado espacio de hipótesis,
$g \in \mathcal{H}$ que se asemeje todo lo posible a la función objetivo
$f$, $g \approx f$.

% Tengo que explicar matemáticamente los tres problemas.
% No sé si para ser algo matemático es la mejor introducción posible.

En el aprendizaje se distinguen muchos problemas, siendo tres los más conocidos:
\begin{itemize}
  \item Regresión.
  \item Clasificación.
  \item Estimación de densidad.
\end{itemize}

Un ejemplo de clasificación sería el siguiente:
sea $\mathcal{X} \subseteq [0,1] \times [0,1]$ e $\mathcal{Y} = \{+1,-1\}$ el espacio
de salida, el cual se puede considerar sí/no, $f$ la función objetivo.
Generando muestras aleatorias, un ejemplo sencillo sería el de la
figura~\ref{fig:dataExample}. En lenguaje natural, tenemos dos características
con las que se puede decidir si un correo electrónico entrante es spam, por ejemplo.
Se necesita una función $g$ que cumpla que $\forall x \in \mathcal{X}$, $g(x) = f(x)$.
Intuitivamente, en el caso de clasificación se busca una función que \emph{separe}
los conjuntos de datos con distintas etiquetas. ¿Existe un separador para este conjunto?
En este caso, \textbf{sí}, siendo además el más sencillo, un separador \emph{lineal}.
Así se puede ver en la figura~\ref{fig:classificationExample}.

<<randomLine, include = FALSE>>=
@

<<signOfPoint, include = FALSE>>=
@

<<dataExample, echo = FALSE, fig.cap="Datos de ejemplo">>=
@

<<classificationExample, echo = FALSE, fig.cap="Primer clasificador">>=
@

En este sencillo caso se puede deducir lo siguiente: en un lado de la recta obtenida
se tienen todos los datos con etiquetas $1$ y en el otro los que tienen etiquetas $-1$.
A los conjuntos de datos que cumplen esto los llamaremos \emph{linealmente separables}.
Este hecho no es lo usual en un problema de aprendizaje real. Ni siquiera se sabe
a priori si, ante nuevos datos, esta recta los seguirá separando correctamente.
Incluso, ante nuevos datos, el conjunto podría pasar a ser no linealmente separable.

\subsection{Factibilidad del aprendizaje}

El aprendizaje estadístico busca \emph{obtener información desde los datos},
utilizando para ello técnicas estadísticas. Se empezará estudiando una cuestión
que se ha planteado antes por encima: ante la llegada de nuevos datos, ¿se tiene
un modelo adecuado? ¿Es factible aprender?

\begin{definicion}
  Error dentro de la muestra ($E_{in}$). Es la fracción de $\mathcal{D}$ donde
  la función escogida $h$ y la objetivo $f$ difieren. $\chi(condicion)$ es la
  función indicadora: vale 1 si la condición es cierta y 0 si no lo es.

  \[
    E_{in}(h) = \frac{1}{N} \sum\limits_{n=1}^N \chi(h(x_n) \neq f(x_n))
  \]
\end{definicion}

\begin{definicion}
  Error fuera de la muestra ($E_{out}$). Es la probabilidad, basada en la distribución
  de $\mathcal{X}$, de que la función escogida $h$ y la objetivo $f$ difieren.

  \[
    E_{out}(h) = \mathbb{P}[h(\textbf{x}) \neq f(\textbf{x})]
  \]
\end{definicion}

% Justificar que E_out es la esperanza de E_in

\begin{teorema}[Desigualdad de Hoeffding]
  Si $X_1, X_2, \ldots, X_n$ son independientes y $a_i \leq X_i \leq b_i \; (i=1,2,\ldots,n)$,
  entonces para $\epsilon>0$ se da:
  \[
    \mathbb{P}\left[ \bar{X} - \mathbb{E}[\bar{X}] \geq \epsilon \right] \leq
    e^{\frac{-2 n^2 \epsilon^2}{\sum\limits_{i=1}^n(b_i-a_i)^2}}
  \]
\end{teorema}

\begin{proof}
  Demostración
\end{proof}

% Meter Hoeffding
% Páginas 22-24 de LfD
% Meter Hoeffding general, con g
% Concluir con la factibilidad con H finito, pag 25-26.

\subsection{Generalización: Teoría de Vapnik-Chervonenkis}
El error fuera de la muestra $E_{out}$ mide la exactitud del modelo generado en
puntos que desconocemos, al contrario que el error dentro de la muestra $E_{in}$,
que se basa en el espacio de entrada $\mathcal{X}$. Expresa así el concepto de
\emph{error de entrenamiento}, por lo que se usarán indistintamente.

En esta sección se generalizará el análisis expuesto en el anterior capítulo.
Se ha discutido que no siempre el valor de $E_{in}$ se generaliza a un valor similar
de $E_{out}$.

\begin{definicion}[Error de generalización]
  Es la diferencia entre $E_{in}$ y $E_{out}$ en valor absoluto.
\end{definicion}

La desigualdad de Hoeffding proporciona una caracterización del error de
generalización con una cota probabilística.

\[
  \mathbb{P}\left[ |E_{in}(g) - E_{out}(g)| > \epsilon \right] \leq
  2 M e^{-2 n \epsilon^2}
\]

Se puede reescribir de esta manera, siendo cierta con una probabilidad de $1-\delta$

\begin{equation}
  \label{eq:generalization}
  E_{out}(g) \leq E_{in}(g) + \sqrt{\frac{1}{2N} \ln \frac{2M}{\delta}} ,\; \delta \ \text{nivel de tolerancia.}
\end{equation}

\begin{proof}
  La desigualdad de Hoeffding dice que con probabilidad al menos $1-2Me^{-2N\epsilon^2}$,
  $|E_{out} - E_{in}| \leq \epsilon \Rightarrow E_{out} \leq E_{in} + \epsilon$.
  Se toma $\delta = 2Me^{-2N\epsilon^2}$, por lo que $\epsilon = \sqrt{\frac{1}{2N} \ln \frac{2M}{\delta}}$
\end{proof}

La otra vuelta de la desigualdad $|E_{out} - E_{in}| \leq \epsilon$ ofrece otro
dato importante, $E_{out}(h) \geq E_{in}(h) - \epsilon \ \forall h \in \mathcal{H}$.
Quiere decir que no se puede realizar un ajuste mucho mejor con otra función del
espacio de hipótesis con mayor $E_{in}$ que la que se ha escogido.

Ahora se necesita trabajar con la ecuación~\ref{eq:generalization} de manera que
el espacio de funciones de hipótesis pueda ser infinito. Si se trabaja tal cual
está, la cota diverge y no ofrecería información alguna.

Tal y como se calculó $M$ en el anterior capítulo, al utilizar las reglas de
probabilidad de supuso que los eventos, como poco, serían disjuntos. Pero esto
no pasa usualmente: los eventos suelen estar solapados, por lo que se debe caracterizar
$M$ de manera distinta para que cuando se trabaje con un espacio infinito, se pueda
obtener una cota finita usando~\ref{eq:generalization}. Supondremos funciones
binarias, por lo que cada $h \in \mathcal{H}$ lleva elementos de $\mathcal{X}$
a $\{-1,+1\}$.

\begin{definicion}
  Sea $x_1,\ldots,x_N \in \mathcal{X}$. Las dicotomías generadas por $\mathcal{H}$
  en esos puntos están definidas por

  \begin{equation}
    \mathcal{H}(x_1,\ldots,x_N) = \{ h(x_1),\ldots,h(x_N) \mid h \in \mathcal{H}  \}
  \end{equation}
\end{definicion}

\begin{definicion}
  La función de crecimiento está definida para un conjunto de hipótesis $\mathcal{H}$
  como
  \begin{equation*}
    m_{\mathcal{H}}(N) = \max_{x_1,\ldots,x_N \in \mathcal{X}} |\mathcal{H}(x_1,\ldots,x_N)|,\
    \text{donde |·| es la cardinalidad del conjunto}
  \end{equation*}
\end{definicion}

$m_{\mathcal{H}}(N)$ es el número máximo de dicotomías que puede generar $\mathcal{H}$
para cualesquiera N puntos. El valor máximo que puede tomar es $|\{-1,+1\}^N|$,
por lo que

\begin{equation*}
  m_{\mathcal{H}}(N) \leq 2^N
\end{equation*}

Si se da la igualdad, quiere decir que $\mathcal{H}$ puede generar todas las
posibles dicotomías en $x_1,\ldots,x_N$, y se dirá que $\mathcal{H}$ puede
\emph{separar} $x_1,\ldots,x_N$.

%Meter algún ejemplo (sólo si da tiempo)

Para cada conjunto de hipótesis que se use, no es fácil calcular de manera exacta
$m_{\mathcal{H}}$, aunque realmente no hay que hacerlo. Como $m_{\mathcal{H}}$
está pensado para sustituir a $M$ en~\ref{eq:generalization}, sólo hay que buscar
una cota superior, así la desigualdad seguirá siendo cierta.

\begin{definicion}
  Si para un determinado dataset de tamaño $k$ $\mathcal{H}$ no puede
  \emph{separarlo}, entonces $k$ es un punto de ruputura para $\mathcal{H}$.
\end{definicion}

Si $k$ es un punto de ruptura, entonces $m_{\mathcal{H}} < 2^k$. Es claro que
para un separador lineal como el de~\ref{fig:classificationExample}, $k=4$.

\begin{ejemplo}
  Tomamos un separador lineal, y $k=3$.
  <<breakExample, echo = FALSE, fig.pos = '!hbt', fig.width = 3, fig.height = 3, fig.cap = 'Ejemplo de punto de ruptura para un separador lineal'>>=
  @

  Como se puede apreciar en la figura~\ref{fig:breakExample}, cualquiera tres
  puntos no alineados pueden ser \emph{separados} por un separador lineal.


  <<anotherbreakExample, echo = FALSE, fig.pos = '!hbt', fig.width = 3, fig.height = 3, fig.cap = 'Ejemplo 2 de punto de ruptura para un separador lineal'>>=
  @

  En cambio, con $k=4$, es fácil ver que no se pueden obtener las $2^4=16$
  dicotomías necesarias para que $k=4$ no sea punto de ruptura. Se puede ver
  en la figura~\ref{fig:anotherbreakExample} que no se pueden clasificar
  correctamente todas las dicotomías de este conjunto.
\end{ejemplo}

Entonces, utilizando este concepto, se va a acotar la función de crecimiento
para cualquier valor de $N$, ya que el hecho de tener punto de ruptura $k$ ofrece
restrucciones sobre el número de dicotomías que puede \emph{separar} $\mathcal{H}$
para un $k' > k$.

Lo más importante acerca de las funciones de crecimiento es que si la condición
$m_{mathcal{H}}=2^N$ se cumple para cada punto, poemos acotar por un polinomio
basado en el pnto de ruptura. 



\subsection{Sobreajuste}

\subsection{Modelos de árboles: Boosting}
